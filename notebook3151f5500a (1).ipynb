{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Code source: Gaël Varoquaux\n# Modified for documentation by Jaques Grobler\n# License: BSD 3 clause\n\nfrom sklearn import datasets\n\nimport matplotlib.pyplot as plt\n\n# Load the digits dataset\ndigits = datasets.load_digits()\n\n# Display the last digit\nplt.figure(1, figsize=(3, 3))\nplt.imshow(digits.images[-1], cmap=plt.cm.gray_r, interpolation=\"nearest\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-28T12:50:24.732274Z","iopub.execute_input":"2022-02-28T12:50:24.732961Z","iopub.status.idle":"2022-02-28T12:50:26.303984Z","shell.execute_reply.started":"2022-02-28T12:50:24.732784Z","shell.execute_reply":"2022-02-28T12:50:26.303025Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Code source: Gaël Varoquaux\n# Modified for documentation by Jaques Grobler\n# License: BSD 3 clause\n\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom sklearn import datasets\nfrom sklearn.decomposition import PCA\n\n# import some data to play with\niris = datasets.load_iris()\nX = iris.data[:, :2]  # we only take the first two features.\ny = iris.target\n\nx_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\ny_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n\nplt.figure(2, figsize=(8, 6))\nplt.clf()\n\n# Plot the training points\nplt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Set1, edgecolor=\"k\")\nplt.xlabel(\"Sepal length\")\nplt.ylabel(\"Sepal width\")\n\nplt.xlim(x_min, x_max)\nplt.ylim(y_min, y_max)\nplt.xticks(())\nplt.yticks(())\n\n# To getter a better understanding of interaction of the dimensions\n# plot the first three PCA dimensions\nfig = plt.figure(1, figsize=(8, 6))\nax = Axes3D(fig, elev=-150, azim=110)\nX_reduced = PCA(n_components=3).fit_transform(iris.data)\nax.scatter(\n    X_reduced[:, 0],\n    X_reduced[:, 1],\n    X_reduced[:, 2],\n    c=y,\n    cmap=plt.cm.Set1,\n    edgecolor=\"k\",\n    s=40,\n)\nax.set_title(\"First three PCA directions\")\nax.set_xlabel(\"1st eigenvector\")\nax.w_xaxis.set_ticklabels([])\nax.set_ylabel(\"2nd eigenvector\")\nax.w_yaxis.set_ticklabels([])\nax.set_zlabel(\"3rd eigenvector\")\nax.w_zaxis.set_ticklabels([])\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-28T12:55:31.262611Z","iopub.execute_input":"2022-02-28T12:55:31.263030Z","iopub.status.idle":"2022-02-28T12:55:31.901213Z","shell.execute_reply.started":"2022-02-28T12:55:31.262988Z","shell.execute_reply":"2022-02-28T12:55:31.893522Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfrom sklearn.datasets import make_classification\nfrom sklearn.datasets import make_blobs\nfrom sklearn.datasets import make_gaussian_quantiles\n\nplt.figure(figsize=(8, 8))\nplt.subplots_adjust(bottom=0.05, top=0.9, left=0.05, right=0.95)\n\nplt.subplot(321)\nplt.title(\"One informative feature, one cluster per class\", fontsize=\"small\")\nX1, Y1 = make_classification(\n    n_features=2, n_redundant=0, n_informative=1, n_clusters_per_class=1\n)\nplt.scatter(X1[:, 0], X1[:, 1], marker=\"o\", c=Y1, s=25, edgecolor=\"k\")\n\nplt.subplot(322)\nplt.title(\"Two informative features, one cluster per class\", fontsize=\"small\")\nX1, Y1 = make_classification(\n    n_features=2, n_redundant=0, n_informative=2, n_clusters_per_class=1\n)\nplt.scatter(X1[:, 0], X1[:, 1], marker=\"o\", c=Y1, s=25, edgecolor=\"k\")\n\nplt.subplot(323)\nplt.title(\"Two informative features, two clusters per class\", fontsize=\"small\")\nX2, Y2 = make_classification(n_features=2, n_redundant=0, n_informative=2)\nplt.scatter(X2[:, 0], X2[:, 1], marker=\"o\", c=Y2, s=25, edgecolor=\"k\")\n\nplt.subplot(324)\nplt.title(\"Multi-class, two informative features, one cluster\", fontsize=\"small\")\nX1, Y1 = make_classification(\n    n_features=2, n_redundant=0, n_informative=2, n_clusters_per_class=1, n_classes=3\n)\nplt.scatter(X1[:, 0], X1[:, 1], marker=\"o\", c=Y1, s=25, edgecolor=\"k\")\n\nplt.subplot(325)\nplt.title(\"Three blobs\", fontsize=\"small\")\nX1, Y1 = make_blobs(n_features=2, centers=3)\nplt.scatter(X1[:, 0], X1[:, 1], marker=\"o\", c=Y1, s=25, edgecolor=\"k\")\n\nplt.subplot(326)\nplt.title(\"Gaussian divided into three quantiles\", fontsize=\"small\")\nX1, Y1 = make_gaussian_quantiles(n_features=2, n_classes=3)\nplt.scatter(X1[:, 0], X1[:, 1], marker=\"o\", c=Y1, s=25, edgecolor=\"k\")\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-28T12:56:24.224998Z","iopub.execute_input":"2022-02-28T12:56:24.226175Z","iopub.status.idle":"2022-02-28T12:56:24.976466Z","shell.execute_reply.started":"2022-02-28T12:56:24.226108Z","shell.execute_reply":"2022-02-28T12:56:24.975558Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.datasets import make_multilabel_classification as make_ml_clf\n\nCOLORS = np.array(\n    [\n        \"!\",\n        \"#FF3333\",  # red\n        \"#0198E1\",  # blue\n        \"#BF5FFF\",  # purple\n        \"#FCD116\",  # yellow\n        \"#FF7216\",  # orange\n        \"#4DBD33\",  # green\n        \"#87421F\",  # brown\n    ]\n)\n\n# Use same random seed for multiple calls to make_multilabel_classification to\n# ensure same distributions\nRANDOM_SEED = np.random.randint(2 ** 10)\n\n\ndef plot_2d(ax, n_labels=1, n_classes=3, length=50):\n    X, Y, p_c, p_w_c = make_ml_clf(\n        n_samples=150,\n        n_features=2,\n        n_classes=n_classes,\n        n_labels=n_labels,\n        length=length,\n        allow_unlabeled=False,\n        return_distributions=True,\n        random_state=RANDOM_SEED,\n    )\n\n    ax.scatter(\n        X[:, 0], X[:, 1], color=COLORS.take((Y * [1, 2, 4]).sum(axis=1)), marker=\".\"\n    )\n    ax.scatter(\n        p_w_c[0] * length,\n        p_w_c[1] * length,\n        marker=\"*\",\n        linewidth=0.5,\n        edgecolor=\"black\",\n        s=20 + 1500 * p_c ** 2,\n        color=COLORS.take([1, 2, 4]),\n    )\n    ax.set_xlabel(\"Feature 0 count\")\n    return p_c, p_w_c\n\n\n_, (ax1, ax2) = plt.subplots(1, 2, sharex=\"row\", sharey=\"row\", figsize=(8, 4))\nplt.subplots_adjust(bottom=0.15)\n\np_c, p_w_c = plot_2d(ax1, n_labels=1)\nax1.set_title(\"n_labels=1, length=50\")\nax1.set_ylabel(\"Feature 1 count\")\n\nplot_2d(ax2, n_labels=3)\nax2.set_title(\"n_labels=3, length=50\")\nax2.set_xlim(left=0, auto=True)\nax2.set_ylim(bottom=0, auto=True)\n\nplt.show()\n\nprint(\"The data was generated from (random_state=%d):\" % RANDOM_SEED)\nprint(\"Class\", \"P(C)\", \"P(w0|C)\", \"P(w1|C)\", sep=\"\\t\")\nfor k, p, p_w in zip([\"red\", \"blue\", \"yellow\"], p_c, p_w_c.T):\n    print(\"%s\\t%0.2f\\t%0.2f\\t%0.2f\" % (k, p, p_w[0], p_w[1]))","metadata":{"execution":{"iopub.status.busy":"2022-02-28T12:56:51.593501Z","iopub.execute_input":"2022-02-28T12:56:51.594061Z","iopub.status.idle":"2022-02-28T12:56:52.184444Z","shell.execute_reply.started":"2022-02-28T12:56:51.594011Z","shell.execute_reply":"2022-02-28T12:56:52.183475Z"},"trusted":true},"execution_count":4,"outputs":[]}]}